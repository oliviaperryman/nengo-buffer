{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the trained weights in an ensemble of neurons\n",
    "- On the function points branch of nengo\n",
    "- On the vision branch of nengo_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nengo\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from nengo_extras.data import load_mnist\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- load the data\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
    "\n",
    "X_train = 2 * X_train - 1  # normalize to -1 to 1\n",
    "X_test = 2 * X_test - 1  # normalize to -1 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit is represented by a one hot vector where the index of the 1 represents the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = np.diag([1]*10)\n",
    "\n",
    "ZERO = temp[0]\n",
    "ONE =  temp[1]\n",
    "TWO =  temp[2]\n",
    "THREE= temp[3]\n",
    "FOUR = temp[4]\n",
    "FIVE = temp[5]\n",
    "SIX =  temp[6]\n",
    "SEVEN =temp[7]\n",
    "EIGHT= temp[8]\n",
    "NINE = temp[9]\n",
    "\n",
    "labels =[ZERO,ONE,TWO,THREE,FOUR,FIVE,SIX,SEVEN,EIGHT,NINE]\n",
    "\n",
    "dim =28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved weight matrices that were created by training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_weights = cPickle.load(open(\"label_weights5000.p\", \"rb\"))\n",
    "activity_to_img_weights = cPickle.load(open(\"activity_to_img_weights5000.p\", \"rb\"))\n",
    "rotated_clockwise_after_encoder_weights =  cPickle.load(open(\"rotated_after_encoder_weights_clockwise5000.p\", \"r\"))\n",
    "rotated_counter_after_encoder_weights =  cPickle.load(open(\"rotated_after_encoder_weights5000.p\", \"r\"))\n",
    "\n",
    "#scale_up_after_encoder_weights = cPickle.load(open(\"scale_up_after_encoder_weights1000.p\",\"r\"))\n",
    "#scale_down_after_encoder_weights = cPickle.load(open(\"scale_down_after_encoder_weights1000.p\",\"r\"))\n",
    "#translate_up_after_encoder_weights = cPickle.load(open(\"translate_up_after_encoder_weights1000.p\",\"r\"))\n",
    "#translate_down_after_encoder_weights = cPickle.load(open(\"translate_down_after_encoder_weights1000.p\",\"r\"))\n",
    "#translate_left_after_encoder_weights = cPickle.load(open(\"translate_left_after_encoder_weights1000.p\",\"r\"))\n",
    "#translate_right_after_encoder_weights = cPickle.load(open(\"translate_right_after_encoder_weights1000.p\",\"r\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#identity_after_encoder_weights = cPickle.load(open(\"identity_after_encoder_weights1000.p\",\"r\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to perform the inhibition of each ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #A value of zero gives no inhibition\n",
    "\n",
    "def inhibit_rotate_clockwise(t):\n",
    "    if t < 1:\n",
    "        return dim**2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def inhibit_rotate_counter(t):\n",
    "    if t < 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return dim**2\n",
    "    \n",
    "def inhibit_identity(t):\n",
    "    if t < 1:\n",
    "        return dim**2\n",
    "    else:\n",
    "        return dim**2\n",
    "    \n",
    "def inhibit_scale_up(t):\n",
    "    return dim**2\n",
    "def inhibit_scale_down(t):\n",
    "    return dim**2\n",
    "\n",
    "def inhibit_translate_up(t):\n",
    "    return dim**2\n",
    "def inhibit_translate_down(t):\n",
    "    return dim**2\n",
    "def inhibit_translate_left(t):\n",
    "    return dim**2\n",
    "def inhibit_translate_right(t):\n",
    "    return dim**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network where the mental imagery and rotation occurs\n",
    "- The state, seed and ensemble parameters (including encoders) must all be the same for the saved weight matrices to work\n",
    "- The number of neurons (n_hid) must be the same as was used for training\n",
    "- The input must be shown for a short period of time to be able to view the rotation\n",
    "- The recurrent connection must be from the neurons because the weight matices were trained on the neuron activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_manipulation(main_ens,weights,inhibition_func):\n",
    "    #create ensemble for manipulation\n",
    "    ens_manipulation = nengo.Ensemble(n_hid,dim**2,seed=3,encoders=encoders, **ens_params)\n",
    "    #create node for inhibition\n",
    "    inhib_manipulation = nengo.Node(inhibition_func)\n",
    "    #Connect the main ensemble to each manipulation ensemble and back with appropriate transformation\n",
    "    nengo.Connection(main_ens.neurons, ens_manipulation.neurons, transform = weights.T, synapse=0.1)\n",
    "    nengo.Connection(ens_manipulation.neurons, main_ens.neurons, transform = weights.T,synapse = 0.1)\n",
    "    #connect inhibition\n",
    "    nengo.Connection(inhib_manipulation, ens_manipulation.neurons, transform=[[-1]] * n_hid)\n",
    "    \n",
    "    #return ens_manipulation,inhib_manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(9)\n",
    "n_hid = 1000\n",
    "model = nengo.Network(seed=3)\n",
    "with model:\n",
    "    #Stimulus only shows for brief period of time\n",
    "    stim = nengo.Node(lambda t: ONE if t < 0.1 else 0) #nengo.processes.PresentInput(labels,1))#\n",
    "    \n",
    "    ens_params = dict(\n",
    "        eval_points=X_train,\n",
    "        neuron_type=nengo.LIF(), #Why not use LIF?\n",
    "        intercepts=nengo.dists.Choice([-0.5]),\n",
    "        max_rates=nengo.dists.Choice([100]),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # linear filter used for edge detection as encoders, more plausible for human visual system\n",
    "    encoders = Gabor().generate(n_hid, (11, 11), rng=rng)\n",
    "    encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
    "\n",
    "\n",
    "    #Ensemble that represents the image with different transformations applied to it\n",
    "    ens = nengo.Ensemble(n_hid, dim**2, seed=3, encoders=encoders, **ens_params)\n",
    "    \n",
    "\n",
    "    #Connect stimulus to ensemble, transform using learned weight matrices\n",
    "    nengo.Connection(stim, ens, transform = np.dot(label_weights,activity_to_img_weights).T)\n",
    "    \n",
    "    #Recurrent connection on the neurons of the ensemble to perform the rotation\n",
    "    #nengo.Connection(ens.neurons, ens.neurons, transform = rotated_counter_after_encoder_weights.T, synapse=0.1)      \n",
    "\n",
    "    \n",
    "    #add_manipulation(ens,rotated_clockwise_after_encoder_weights, inhibit_rotate_clockwise)\n",
    "    add_manipulation(ens,rotated_counter_after_encoder_weights, inhibit_rotate_counter)\n",
    "    add_manipulation(ens,scale_up_after_encoder_weights, inhibit_scale_up)\n",
    "    #add_manipulation(ens,scale_down_after_encoder_weights, inhibit_scale_down)\n",
    "    #add_manipulation(ens,translate_up_after_encoder_weights, inhibit_translate_up)\n",
    "    #add_manipulation(ens,translate_down_after_encoder_weights, inhibit_translate_down)\n",
    "    #add_manipulation(ens,translate_left_after_encoder_weights, inhibit_translate_left)\n",
    "    #add_manipulation(ens,translate_right_after_encoder_weights, inhibit_translate_right)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #Collect output, use synapse for smoothing\n",
    "    probe = nengo.Probe(ens.neurons,synapse=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 0:01:05.                                                 \n"
     ]
    }
   ],
   "source": [
    "sim.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is not part of the brain model, it is used to view the output for the ensemble\n",
    "Since it's probing the neurons themselves, the output must be transformed from neuron activity to visual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Animation for Probe output'''\n",
    "fig = plt.figure()\n",
    "\n",
    "output_acts = []\n",
    "for act in sim.data[probe]:\n",
    "    output_acts.append(np.dot(act,activity_to_img_weights))\n",
    "\n",
    "def updatefig(i):\n",
    "    im = pylab.imshow(np.reshape(output_acts[i],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'),animated=True)\n",
    "    \n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, interval=100, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(sim.data[probe]))\n",
    "\n",
    "plt.subplot(161)\n",
    "plt.title(\"100\")\n",
    "pylab.imshow(np.reshape(output_acts[100],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(162)\n",
    "plt.title(\"500\")\n",
    "pylab.imshow(np.reshape(output_acts[500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(163)\n",
    "plt.title(\"1000\")\n",
    "pylab.imshow(np.reshape(output_acts[1000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(164)\n",
    "plt.title(\"1500\")\n",
    "pylab.imshow(np.reshape(output_acts[1500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(165)\n",
    "plt.title(\"2000\")\n",
    "pylab.imshow(np.reshape(output_acts[2000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(166)\n",
    "plt.title(\"2500\")\n",
    "pylab.imshow(np.reshape(output_acts[2500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the probe's output if it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The filename includes the number of neurons and which digit is being rotated\n",
    "filename = \"mental_rotation_output_ONE_\"  + str(n_hid) + \".p\"\n",
    "cPickle.dump(sim.data[probe], open( filename , \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(testing,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get image\n",
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=testing)\n",
    "\n",
    "#Get rotated encoder outputs\n",
    "testing_rotate = np.dot(testing_act,rotated_after_encoder_weights)\n",
    "\n",
    "#Get activities\n",
    "testing_rotate = ens.neuron_type.rates(testing_rotate, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "for i in range(5):\n",
    "    testing_rotate = np.dot(testing_rotate,rotated_after_encoder_weights)\n",
    "    testing_rotate = ens.neuron_type.rates(testing_rotate, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "\n",
    "#testing_rotate = np.dot(testing_rotate,rotation_weights)\n",
    "\n",
    "testing_rotate = np.dot(testing_rotate,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_rotate,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(X_train[0],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=X_train[0])\n",
    "\n",
    "testing_rotate = np.dot(testing_act,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_rotate,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letterO = np.dot(ZERO,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(161)\n",
    "pylab.imshow(np.reshape(letterO,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterL = np.dot(SEVEN,label_weights)\n",
    "for _ in range(30):\n",
    "    letterL = np.dot(letterL,rotation_weights)\n",
    "letterL = np.dot(letterL,activity_to_img_weights)\n",
    "plt.subplot(162)\n",
    "pylab.imshow(np.reshape(letterL,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterI = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(163)\n",
    "pylab.imshow(np.reshape(letterI,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(165)\n",
    "pylab.imshow(np.reshape(letterI,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterV = np.dot(SEVEN,label_weights)\n",
    "for _ in range(40):\n",
    "    letterV = np.dot(letterV,rotation_weights)\n",
    "letterV = np.dot(letterV,activity_to_img_weights)\n",
    "plt.subplot(164)\n",
    "pylab.imshow(np.reshape(letterV,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterA = np.dot(SEVEN,label_weights)\n",
    "for _ in range(10):\n",
    "    letterA = np.dot(letterA,rotation_weights)\n",
    "letterA = np.dot(letterA,activity_to_img_weights)\n",
    "plt.subplot(166)\n",
    "pylab.imshow(np.reshape(letterA,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
