{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Ensemble on MNIST Dataset \n",
    "- On the function points branch of nengo\n",
    "- On the vision branch of nengo_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nengo\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import pylab\n",
    "from PIL import Image\n",
    "import nengo.spa as spa\n",
    "import cPickle\n",
    "import random\n",
    "\n",
    "from nengo_extras.data import load_mnist\n",
    "from nengo_extras.vision import Gabor, Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent each number using a one-hot where the index of the one represents the digit value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode categorical integer features using a one-hot aka one-of-K scheme.\n",
    "def one_hot(labels, c=None):\n",
    "    assert labels.ndim == 1\n",
    "    n = labels.shape[0]\n",
    "    c = len(np.unique(labels)) if c is None else c\n",
    "    y = np.zeros((n, c))\n",
    "    y[np.arange(n), labels] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST training and testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- load the data\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
    "\n",
    "X_train = 2 * X_train - 1  # normalize to -1 to 1\n",
    "X_test = 2 * X_test - 1  # normalize to -1 to 1\n",
    "\n",
    "train_targets = one_hot(y_train, 10)\n",
    "test_targets = one_hot(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Network\n",
    "- The network parameters must be the same here as when the weight matrices are used later on\n",
    "- The network is made up of an ensemble and two nodes\n",
    "  - The first connection ( to v) computes the weights from the activities of the images to the images themselves\n",
    "  - The second connection (to v2) computes the weights from the activities of the images to the labels\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x4750e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQuET0iH/D314AFf3bNkwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4eb1400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = np.random.RandomState(9)\n",
    "\n",
    "# --- set up network parameters\n",
    "#Want to encode and decode the image\n",
    "n_vis = X_train.shape[1]\n",
    "n_out =  X_train.shape[1]\n",
    "#number of neurons/dimensions of semantic pointer\n",
    "n_hid = 1000 #Try with more neurons for more accuracy\n",
    "\n",
    "\n",
    "#Want the encoding/decoding done on the training images\n",
    "ens_params = dict(\n",
    "    eval_points=X_train,\n",
    "    neuron_type=nengo.LIF(), #Why not use LIF? originally used LIFRate()\n",
    "    intercepts=nengo.dists.Choice([-0.5]),\n",
    "    max_rates=nengo.dists.Choice([100]),\n",
    "    )\n",
    "\n",
    "\n",
    "#Least-squares solver with L2 regularization.\n",
    "solver = nengo.solvers.LstsqL2(reg=0.01)\n",
    "#solver = nengo.solvers.LstsqL2(reg=0.0001)\n",
    "solver2 = nengo.solvers.LstsqL2(reg=0.01)\n",
    "\n",
    "#network that generates the weight matrices between neuron activity and images and the labels\n",
    "with nengo.Network(seed=3) as model:\n",
    "    a = nengo.Ensemble(n_hid, n_vis, seed=3, **ens_params)\n",
    "    v = nengo.Node(size_in=n_out)\n",
    "    conn = nengo.Connection(\n",
    "        a, v, synapse=None,\n",
    "        eval_points=X_train, function=X_train,#want the same thing out (identity)\n",
    "        solver=solver)\n",
    "    \n",
    "    v2 = nengo.Node(size_in=train_targets.shape[1])\n",
    "    conn2 = nengo.Connection(\n",
    "        a, v2, synapse=None,\n",
    "        eval_points=X_train, function=train_targets, #Want to get the labels out\n",
    "        solver=solver2)\n",
    "    \n",
    "\n",
    "# linear filter used for edge detection as encoders, more plausible for human visual system\n",
    "encoders = Gabor().generate(n_hid, (11, 11), rng=rng)\n",
    "encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
    "#Set the ensembles encoders to this\n",
    "a.encoders = encoders\n",
    "\n",
    "#Check the encoders were correctly made\n",
    "plt.imshow(encoders[0].reshape(28, 28), vmin=encoders[0].min(), vmax=encoders[0].max(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the network statically\n",
    "- Functions for computing representation of the image at different levels of encoding/decoding\n",
    "- get_outs  returns the output of the network\n",
    "- able to evaluate on many images\n",
    "- no need to run the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the one hot labels for the images\n",
    "def get_outs(sim, images):\n",
    "    #The activity of the neurons when an image is given as input\n",
    "    _, acts = nengo.utils.ensemble.tuning_curves(a, sim, inputs=images)\n",
    "    #The activity multiplied by the weight matrix (calculated in the network) to give the one-hot labels\n",
    "    return np.dot(acts, sim.data[conn2].weights.T)\n",
    "\n",
    "#Check how many of the labels were produced correctly\n",
    "#def get_error(sim, images, labels):\n",
    "#    return np.argmax(get_outs(sim, images), axis=1) != labels\n",
    "\n",
    "#Get label of the images\n",
    "#def get_labels(sim,images):\n",
    "#    return np.argmax(get_outs(sim, images), axis=1)\n",
    "\n",
    "#Get the neuron activity of an image or group of images (this is the semantic pointer in this case)\n",
    "def get_activities(sim, images):\n",
    "    _, acts = nengo.utils.ensemble.tuning_curves(a, sim, inputs=images)\n",
    "    return acts\n",
    "\n",
    "#Get the representation of the image after it has gone through the encoders (Gabor filters) but before it is in the neurons\n",
    "#This must be computed to create the weight matrix for rotation from neuron activity to this step\n",
    "# This allows a recurrent connection to be made from the neurons to themselves later\n",
    "def get_encoder_outputs(sim,images):\n",
    "    #Pass the images through the encoders\n",
    "    outs = np.dot(images,sim.data[a].encoders.T) #before the neurons \n",
    "    return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "Create lists of training and testing images\n",
    "- Original images at random orientations\n",
    "- Those images rotated a fixed amount more\n",
    "- Images not used for training, but later for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim =28\n",
    "#Scale an image\n",
    "def scale(img, scale):\n",
    "    newImg = scipy.ndimage.interpolation.zoom(np.reshape(img, (dim,dim), 'F').T,scale,cval=-1)\n",
    "    #If its scaled up\n",
    "    if(scale >1):\n",
    "        newImg = newImg[len(newImg)/2-(dim/2):-(len(newImg)/2-(dim/2)),len(newImg)/2-(dim/2):-(len(newImg)/2-(dim/2))]\n",
    "        if len(newImg) >28:\n",
    "            newImg = newImg[:28,:28]\n",
    "        newImg = newImg.ravel()\n",
    "    else: #Scaled down\n",
    "        m = np.zeros((dim,dim))\n",
    "        m.fill(-1)\n",
    "        m[(dim-len(newImg))/2:(dim-len(newImg))/2+len(newImg),(dim-len(newImg))/2:(dim-len(newImg))/2+len(newImg)] = newImg\n",
    "        newImg = m\n",
    "    return newImg.ravel()\n",
    "\n",
    "#Shift an image\n",
    "def translate(img,x,y):\n",
    "    newImg = scipy.ndimage.interpolation.shift(np.reshape(img, (dim,dim), 'F'),(x,y), cval=-1)\n",
    "    return newImg.T.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Images to train, starting at random orientation, size and translation\n",
    "orig_imgs = X_train[:100000].copy()\n",
    "for img in orig_imgs:\n",
    "    while True:\n",
    "        try:\n",
    "            img[:] = scale(img,random.uniform(0.5,1.5))\n",
    "            break\n",
    "        except:\n",
    "            img[:] = img\n",
    "    img[:] = scipy.ndimage.interpolation.rotate(np.reshape(img,(28,28)),\n",
    "                                                (np.random.randint(360)),reshape=False,mode=\"nearest\").ravel()\n",
    "    img[:] = translate(img,random.randint(-6,6),random.randint(-6,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dec556b2a177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Check to make sure images were generated correctly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m122\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#Check to make sure images were generated correctly\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(orig_imgs[random.randint(0,1000)],(28,28)), cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(orig_imgs[random.randint(0,1000)],(28,28)), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving weight matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"activity_to_img_weights_all_transformations\" + str(n_hid) +\".p\"\n",
    "cPickle.dump(sim.data[conn].weights.T, open( filename, \"wb\" ) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
