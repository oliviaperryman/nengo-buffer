{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the trained weights in an ensemble of neurons\n",
    "- On the function points branch of nengo\n",
    "- On the vision branch of nengo_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nengo\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from nengo_extras.data import load_mnist\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- load the data\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
    "\n",
    "X_train = 2 * X_train - 1  # normalize to -1 to 1\n",
    "X_test = 2 * X_test - 1  # normalize to -1 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit is represented by a one hot vector where the index of the 1 represents the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = np.diag([1]*10)\n",
    "\n",
    "ZERO = temp[0]\n",
    "ONE =  temp[1]\n",
    "TWO =  temp[2]\n",
    "THREE= temp[3]\n",
    "FOUR = temp[4]\n",
    "FIVE = temp[5]\n",
    "SIX =  temp[6]\n",
    "SEVEN =temp[7]\n",
    "EIGHT= temp[8]\n",
    "NINE = temp[9]\n",
    "\n",
    "labels =[ZERO,ONE,TWO,THREE,FOUR,FIVE,SIX,SEVEN,EIGHT,NINE]\n",
    "\n",
    "dim =28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved weight matrices that were created by training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_weights = cPickle.load(open(\"label_weights5000.p\", \"rb\"))\n",
    "activity_to_img_weights = cPickle.load(open(\"activity_to_img_weights5000.p\", \"rb\"))\n",
    "rotated_clockwise_after_encoder_weights =  cPickle.load(open(\"rotated_after_encoder_weights_clockwise5000.p\", \"r\"))\n",
    "rotated_counter_after_encoder_weights =  cPickle.load(open(\"rotated_after_encoder_weights5000.p\", \"r\"))\n",
    "\n",
    "#identity_after_encoder_weights = cPickle.load(open(\"identity_after_encoder_weights1000.p\",\"r\"))\n",
    "\n",
    "\n",
    "#rotation_clockwise_weights = cPickle.load(open(\"rotation_clockwise_weights1000.p\",\"rb\"))\n",
    "#rotation_counter_weights = cPickle.load(open(\"rotation_weights1000.p\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_pass_weights = cPickle.load(open(\"low_pass_weights1000.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to perform the inhibition of each ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #A value of zero gives no inhibition\n",
    "\n",
    "def inhibit_rotate_clockwise(t):\n",
    "    if t < 0.5:\n",
    "        return dim**2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def inhibit_rotate_counter(t):\n",
    "    if t < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return dim**2\n",
    "    \n",
    "def inhibit_identity(t):\n",
    "    if t < 0.3:\n",
    "        return dim**2\n",
    "    else:\n",
    "        return dim**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intense(img):\n",
    "    newImg = img.copy()\n",
    "    newImg[newImg < -0.1] = -1\n",
    "    newImg[newImg > -0.1] = 1\n",
    "    return newImg\n",
    "\n",
    "def node_func(t,x):\n",
    "    clean = scipy.ndimage.gaussian_filter(x, sigma=2)\n",
    "    #clean = scipy.ndimage.median_filter(x, 3)\n",
    "    clean = intense(clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network where the mental imagery and rotation occurs\n",
    "- The state, seed and ensemble parameters (including encoders) must all be the same for the saved weight matrices to work\n",
    "- The number of neurons (n_hid) must be the same as was used for training\n",
    "- The input must be shown for a short period of time to be able to view the rotation\n",
    "- The recurrent connection must be from the neurons because the weight matices were trained on the neuron activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(9)\n",
    "n_hid = 5000\n",
    "model = nengo.Network(seed=3)\n",
    "with model:\n",
    "    #Stimulus only shows for brief period of time\n",
    "    stim = nengo.Node(lambda t: THREE if t < 0.1 else 0) #nengo.processes.PresentInput(labels,1))#\n",
    "    \n",
    "    ens_params = dict(\n",
    "        eval_points=X_train,\n",
    "        neuron_type=nengo.LIF(), #Why not use LIF?\n",
    "        intercepts=nengo.dists.Choice([-0.5]),\n",
    "        max_rates=nengo.dists.Choice([100]),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # linear filter used for edge detection as encoders, more plausible for human visual system\n",
    "    encoders = Gabor().generate(n_hid, (11, 11), rng=rng)\n",
    "    encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
    "\n",
    "\n",
    "    #Ensemble that represents the image with different transformations applied to it\n",
    "    ens = nengo.Ensemble(n_hid, dim**2, seed=3, encoders=encoders, **ens_params)\n",
    "    \n",
    "\n",
    "    #Connect stimulus to ensemble, transform using learned weight matrices\n",
    "    nengo.Connection(stim, ens, transform = np.dot(label_weights,activity_to_img_weights).T)\n",
    "    \n",
    "    #Recurrent connection on the neurons of the ensemble to perform the rotation\n",
    "    #nengo.Connection(ens.neurons, ens.neurons, transform = rotated_counter_after_encoder_weights.T, synapse=0.1)      \n",
    "    #nengo.Connection(ens.neurons, ens.neurons, transform = low_pass_weights.T, synapse=0.1)      \n",
    "\n",
    "    #Identity ensemble\n",
    "    #ens_iden = nengo.Ensemble(n_hid,dim**2, seed=3, encoders=encoders, **ens_params)\n",
    "    #Rotation ensembles\n",
    "    #ens_clock_rot = nengo.Ensemble(n_hid,dim**2,seed=3,encoders=encoders, **ens_params)\n",
    "    ens_counter_rot = nengo.Ensemble(n_hid,dim**2,seed=3,encoders=encoders, **ens_params)\n",
    "    \n",
    "    \n",
    "    #Inhibition nodes\n",
    "    #inhib_iden = nengo.Node(inhibit_identity)\n",
    "    #inhib_clock_rot = nengo.Node(inhibit_rotate_clockwise)\n",
    "    #inhib_counter_rot = nengo.Node(inhibit_rotate_counter)\n",
    "\n",
    "    #Connect the main ensemble to each manipulation ensemble and back with appropriate transformation\n",
    "    #Identity\n",
    "    #nengo.Connection(ens.neurons, ens_iden.neurons,transform=identity_after_encoder_weights.T,synapse=0.1)\n",
    "    #nengo.Connection(ens_iden.neurons, ens.neurons,transform=identity_after_encoder_weights.T,synapse=0.1)\n",
    "    #Clockwise\n",
    "    #nengo.Connection(ens.neurons, ens_clock_rot.neurons, transform = rotated_clockwise_after_encoder_weights.T,synapse=0.1)\n",
    "    #nengo.Connection(ens_clock_rot.neurons, ens.neurons, transform = rotated_clockwise_after_encoder_weights.T,synapse = 0.1)\n",
    "    #Counter-clockwise\n",
    "    #nengo.Connection(ens.neurons, ens_counter_rot.neurons, transform = rotated_counter_after_encoder_weights.T, synapse=0.1)\n",
    "    nengo.Connection(ens_counter_rot.neurons, ens.neurons, transform = rotated_counter_after_encoder_weights.T, synapse=0.1)\n",
    "  \n",
    "    #nengo.Connection(ens.neurons, ens_counter_rot.neurons, transform = low_pass_weights.T, synapse=0.1)\n",
    "    #nengo.Connection(ens_counter_rot.neurons, ens.neurons, transform = low_pass_weights.T, synapse=0.1)\n",
    "\n",
    "    n = nengo.Node(node_func, size_in=dim**2)\n",
    "    nengo.Connection(ens.neurons,n,transform=activity_to_img_weights.T, synapse=0.1)\n",
    "    nengo.Connection(n,ens_counter_rot,synapse=0.1)\n",
    "\n",
    "    #Connect the inhibition nodes to each manipulation ensemble\n",
    "    #nengo.Connection(inhib_iden, ens_iden.neurons, transform=[[-1]] * n_hid)\n",
    "    #nengo.Connection(inhib_clock_rot, ens_clock_rot.neurons, transform=[[-1]] * n_hid)\n",
    "    #nengo.Connection(inhib_counter_rot, ens_counter_rot.neurons, transform=[[-1]] * n_hid)\n",
    "\n",
    "    \n",
    "    #Collect output, use synapse for smoothing\n",
    "    probe = nengo.Probe(ens.neurons,synapse=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is not part of the brain model, it is used to view the output for the ensemble\n",
    "Since it's probing the neurons themselves, the output must be transformed from neuron activity to visual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Animation for Probe output'''\n",
    "fig = plt.figure()\n",
    "\n",
    "output_acts = []\n",
    "for act in sim.data[probe]:\n",
    "    output_acts.append(np.dot(act,activity_to_img_weights))\n",
    "\n",
    "def updatefig(i):\n",
    "    im = pylab.imshow(np.reshape(output_acts[i],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'),animated=True)\n",
    "    \n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, interval=0.1, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ouput_acts = sim.data[probe]\n",
    "\n",
    "plt.subplot(261)\n",
    "plt.title(\"100\")\n",
    "pylab.imshow(np.reshape(output_acts[100],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(262)\n",
    "plt.title(\"500\")\n",
    "pylab.imshow(np.reshape(output_acts[500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(263)\n",
    "plt.title(\"1000\")\n",
    "pylab.imshow(np.reshape(output_acts[1000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(264)\n",
    "plt.title(\"1500\")\n",
    "pylab.imshow(np.reshape(output_acts[1500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(265)\n",
    "plt.title(\"2000\")\n",
    "pylab.imshow(np.reshape(output_acts[2000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(266)\n",
    "plt.title(\"2500\")\n",
    "pylab.imshow(np.reshape(output_acts[2500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(267)\n",
    "plt.title(\"3000\")\n",
    "pylab.imshow(np.reshape(output_acts[3000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(268)\n",
    "plt.title(\"3500\")\n",
    "pylab.imshow(np.reshape(output_acts[3500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(269)\n",
    "plt.title(\"4000\")\n",
    "pylab.imshow(np.reshape(output_acts[4000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(2,6,10)\n",
    "plt.title(\"4500\")\n",
    "pylab.imshow(np.reshape(output_acts[4500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(2,6,11)\n",
    "plt.title(\"5000\")\n",
    "pylab.imshow(np.reshape(output_acts[4999],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the probe's output if it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The filename includes the number of neurons and which digit is being rotated\n",
    "filename = \"mental_rotation_output_ONE_\"  + str(n_hid) + \".p\"\n",
    "cPickle.dump(sim.data[probe], open( filename , \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(testing,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get image\n",
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=testing)\n",
    "\n",
    "#Get clean encoder outputs\n",
    "testing_low_pass = np.dot(testing_act,low_pass_weights)\n",
    "\n",
    "#Get activities\n",
    "testing_low_pass = ens.neuron_type.rates(testing_low_pass, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "#for i in range(5):\n",
    "#    testing_rotate = np.dot(testing_low_pass,low_pass_weights)\n",
    "#    testing_rotate = ens.neuron_type.rates(testing_low_pass, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "\n",
    "#testing_rotate = np.dot(testing_rotate,rotation_weights)\n",
    "\n",
    "testing_low_pass = np.dot(testing_low_pass,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_low_pass,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(X_train[0],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=X_train[0])\n",
    "\n",
    "testing_rotate = np.dot(testing_act,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_rotate,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letterO = np.dot(ZERO,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(161)\n",
    "pylab.imshow(np.reshape(letterO,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterL = np.dot(SEVEN,label_weights)\n",
    "for _ in range(30):\n",
    "    letterL = np.dot(letterL,rotation_weights)\n",
    "letterL = np.dot(letterL,activity_to_img_weights)\n",
    "plt.subplot(162)\n",
    "pylab.imshow(np.reshape(letterL,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterI = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(163)\n",
    "pylab.imshow(np.reshape(letterI,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(165)\n",
    "pylab.imshow(np.reshape(letterI,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterV = np.dot(SEVEN,label_weights)\n",
    "for _ in range(40):\n",
    "    letterV = np.dot(letterV,rotation_weights)\n",
    "letterV = np.dot(letterV,activity_to_img_weights)\n",
    "plt.subplot(164)\n",
    "pylab.imshow(np.reshape(letterV,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterA = np.dot(SEVEN,label_weights)\n",
    "for _ in range(10):\n",
    "    letterA = np.dot(letterA,rotation_weights)\n",
    "letterA = np.dot(letterA,activity_to_img_weights)\n",
    "plt.subplot(166)\n",
    "pylab.imshow(np.reshape(letterA,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
