{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare similarity of image after rotation\n",
    "- On the function points branch of nengo\n",
    "- On the vision branch of nengo_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nengo\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from nengo_extras.data import load_mnist\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import scipy.ndimage\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- load the data\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
    "\n",
    "X_train = 2 * X_train - 1  # normalize to -1 to 1\n",
    "X_test = 2 * X_test - 1  # normalize to -1 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit is represented by a one hot vector where the index of the 1 represents the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = np.diag([1]*10)\n",
    "\n",
    "ZERO = temp[0]\n",
    "ONE =  temp[1]\n",
    "TWO =  temp[2]\n",
    "THREE= temp[3]\n",
    "FOUR = temp[4]\n",
    "FIVE = temp[5]\n",
    "SIX =  temp[6]\n",
    "SEVEN =temp[7]\n",
    "EIGHT= temp[8]\n",
    "NINE = temp[9]\n",
    "\n",
    "labels =[ZERO,ONE,TWO,THREE,FOUR,FIVE,SIX,SEVEN,EIGHT,NINE]\n",
    "\n",
    "dim =28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved weight matrices that were created by training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_weights = cPickle.load(open(\"label_weights1000.p\", \"rb\"))\n",
    "activity_to_img_weights = cPickle.load(open(\"activity_to_img_weights1000.p\", \"rb\"))\n",
    "#rotated_clockwise_after_encoder_weights =  cPickle.load(open(\"rotated_after_encoder_weights_clockwise5000.p\", \"r\"))\n",
    "rotated_counter_after_encoder_weights =  cPickle.load(open(\"rotated_after_encoder_weights1000.p\", \"r\"))\n",
    "\n",
    "two_img_similarity_ssim_weights = cPickle.load(open(\"two_img_similarity_ssim_weights2000.p\"))\n",
    "two_img_similarity_dot_weights = cPickle.load(open(\"two_img_similarity_dot_weights2000.p\"))\n",
    "two_img_similarity_cosine_sim_weights = cPickle.load(open(\"two_img_similarity_cosine_sim_weights2_2000.p\"))\n",
    "\n",
    "#identity_after_encoder_weights = cPickle.load(open(\"identity_after_encoder_weights1000.p\",\"r\"))\n",
    "\n",
    "\n",
    "#rotation_clockwise_weights = cPickle.load(open(\"rotation_clockwise_weights1000.p\",\"rb\"))\n",
    "#rotation_counter_weights = cPickle.load(open(\"rotation_weights1000.p\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to perform the inhibition of each ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create stimulus at angle\n",
    "weight = np.dot(label_weights,activity_to_img_weights)\n",
    "\n",
    "img = np.dot(THREE,weight)\n",
    "\n",
    "plt.subplot(121)\n",
    "pylab.imshow(img.reshape(28,28),cmap=\"gray\")\n",
    "\n",
    "\n",
    "#img =X_train[7] \n",
    "rot_img =scipy.ndimage.interpolation.rotate(img.reshape(28,28),-60,reshape=False,cval=-1).ravel()\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(rot_img.reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''For direct mode and nodes\n",
    "def ssim_func(x):\n",
    "    \n",
    "    img1 = np.dot(x[:1000],activity_to_img_weights)\n",
    "    img2 = np.dot(x[1000:],activity_to_img_weights)\n",
    "    return ssim(img1.reshape(28,28),img2.reshape(28,28))\n",
    "\n",
    "def activity_sim_func(x):\n",
    "    u=x[:1000]\n",
    "    v=x[1000:]\n",
    "    \n",
    "    #a= nengo.spa.similarity(u,v,normalize=True)\n",
    "    a = np.dot(u,v)\n",
    "    \n",
    "    return a\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network where the mental imagery and rotation occurs\n",
    "- The state, seed and ensemble parameters (including encoders) must all be the same for the saved weight matrices to work\n",
    "- The number of neurons (n_hid) must be the same as was used for training\n",
    "- The input must be shown for a short period of time to be able to view the rotation\n",
    "- The recurrent connection must be from the neurons because the weight matices were trained on the neuron activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(9)\n",
    "n_hid = 1000\n",
    "model = nengo.Network(seed=3)\n",
    "with model:\n",
    "    #Stimulus to be matched to\n",
    "    static_stim = nengo.Node(img)\n",
    "    \n",
    "    #Stimulus only shows for brief period of time\n",
    "    rot_stim = nengo.Node(lambda t: rot_img if t < 0.1 else 0)\n",
    "    \n",
    "    \n",
    "    ens_params = dict(\n",
    "        eval_points=X_train,\n",
    "        neuron_type=nengo.LIF(), \n",
    "        intercepts=nengo.dists.Choice([-0.5]),\n",
    "        max_rates=nengo.dists.Choice([100]),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # linear filter used for edge detection as encoders, more plausible for human visual system\n",
    "    encoders = Gabor().generate(n_hid, (11, 11), rng=rng)\n",
    "    encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
    "\n",
    "    #Ensemble that represents the image to be matched\n",
    "    static_ens = nengo.Ensemble(n_neurons=n_hid, dimensions=784,seed=3, encoders=encoders, **ens_params) #Direct? cannot because similarity between activities\n",
    "    nengo.Connection(static_stim, static_ens)\n",
    "    \n",
    "    #Ensemble that represents the image and will be rotated\n",
    "    ens = nengo.Ensemble(n_hid, dim**2, seed=3, encoders=encoders, **ens_params)\n",
    "    \n",
    "\n",
    "    #Connect stimulus to ensemble, transform using learned weight matrices\n",
    "    nengo.Connection(rot_stim, ens)\n",
    "    \n",
    "    #Recurrent connection on the neurons of the ensemble to perform the rotation\n",
    "    nengo.Connection(ens.neurons, ens.neurons, transform = rotated_counter_after_encoder_weights.T, synapse=0.1)\n",
    "\n",
    "    '''\n",
    "    #combine ens has different parameters\n",
    "    ens_params_combine = dict(\n",
    "        eval_points=imgs, \n",
    "        neuron_type=nengo.LIF(), #originally used LIFRate()\n",
    "        intercepts=nengo.dists.Choice([-0.5]),\n",
    "        max_rates=nengo.dists.Choice([100]),\n",
    "    )\n",
    "    \n",
    "    encoders_combine = Gabor().generate(n_hid*2, (11, 11), rng=rng)\n",
    "    encoders_combine = Mask((56, 28)).populate(encoders_combine, rng=rng, flatten=True)\n",
    "    '''\n",
    "    #Bring two images together to calculate similarity\n",
    "    combine = nengo.Ensemble(2000, 784*2)#,seed=3,encoders=encoders_combine,**ens_params_combine) #Not direct, connections to actual neurons\n",
    "    #combine = nengo.Ensemble(1000, 10000, neuron_type=nengo.Direct())\n",
    "    \n",
    "    #Connect the ensembles into one larger ensemble\n",
    "    nengo.Connection(static_ens.neurons,combine.neurons[:1000])\n",
    "    nengo.Connection(ens.neurons, combine.neurons[1000:])\n",
    "    \n",
    "    #structural similarity measure\n",
    "    ssim_node = nengo.Node(None, size_in=1)\n",
    "    nengo.Connection(combine.neurons, ssim_node, transform=two_img_similarity_ssim_weights)\n",
    "    \n",
    "    #Trained similarity of activities using dot product\n",
    "    activity_sim_node = nengo.Node(None,size_in=1)\n",
    "    nengo.Connection(combine.neurons, activity_sim_node, transform=two_img_similarity_dot_weights)\n",
    "    \n",
    "    #Trained similarity of activities using cosine similarity\n",
    "    activity_cosine_sim_node = nengo.Node(None, size_in=1)\n",
    "    nengo.Connection(combine.neurons, activity_cosine_sim_node, transform=two_img_similarity_cosine_sim_weights)\n",
    "    \n",
    "    #Collect output, use synapse for smoothing\n",
    "    probe = nengo.Probe(ens.neurons,synapse=0.1)\n",
    "    static_probe = nengo.Probe(static_ens.neurons,synapse=0.1)\n",
    "    ssim_probe = nengo.Probe(ssim_node,synapse=0.1)\n",
    "    activity_sim_probe = nengo.Probe(activity_sim_node,synapse=0.1)\n",
    "    cosine_sim_probe = nengo.Probe(activity_cosine_sim_node,synapse=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is not part of the brain model, it is used to view the output for the ensemble\n",
    "Since it's probing the neurons themselves, the output must be transformed from neuron activity to visual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#Graph of probe output\n",
    "plt.plot(sim.trange(), sim.data[ssim_probe], 'k', label=\"Trained SSIM\")\n",
    "plt.legend()\n",
    "plt.xlim((0,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Graph of probe output\n",
    "plt.plot(sim.trange(), sim.data[cosine_sim_probe], 'k', label=\"Trained Cosine Similarity\")\n",
    "plt.legend()\n",
    "plt.xlim((0,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Graph of probe output\n",
    "plt.plot(sim.trange(), sim.data[activity_sim_probe], 'k', label=\"Trained Similarity Dot Product\")\n",
    "plt.legend()\n",
    "plt.xlim((0,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Turn probe activity to img\n",
    "output_acts = []\n",
    "for act in sim.data[probe]:\n",
    "    output_acts.append(np.dot(act,activity_to_img_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Animation for Probe output'''\n",
    "fig = plt.figure()\n",
    "\n",
    "\n",
    "def updatefig(i):\n",
    "    im = pylab.imshow(np.reshape(output_acts[i],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'),animated=True)\n",
    "    \n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, interval=0.1, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ouput_acts = sim.data[probe]\n",
    "\n",
    "plt.subplot(261)\n",
    "plt.title(\"100\")\n",
    "pylab.imshow(np.reshape(output_acts[100],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(262)\n",
    "plt.title(\"500\")\n",
    "pylab.imshow(np.reshape(output_acts[500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(263)\n",
    "plt.title(\"1000\")\n",
    "pylab.imshow(np.reshape(output_acts[1000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(264)\n",
    "plt.title(\"1500\")\n",
    "pylab.imshow(np.reshape(output_acts[1500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(265)\n",
    "plt.title(\"2000\")\n",
    "pylab.imshow(np.reshape(output_acts[2000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(266)\n",
    "plt.title(\"2500\")\n",
    "pylab.imshow(np.reshape(output_acts[2500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(267)\n",
    "plt.title(\"3000\")\n",
    "pylab.imshow(np.reshape(output_acts[3000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(268)\n",
    "plt.title(\"3500\")\n",
    "pylab.imshow(np.reshape(output_acts[3500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(269)\n",
    "plt.title(\"4000\")\n",
    "pylab.imshow(np.reshape(output_acts[4000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(2,6,10)\n",
    "plt.title(\"4500\")\n",
    "pylab.imshow(np.reshape(output_acts[4500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(2,6,11)\n",
    "plt.title(\"5000\")\n",
    "pylab.imshow(np.reshape(output_acts[4999],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.subplot(171)\n",
    "plt.title(\"0.1\")\n",
    "fig.axes.get_xaxis().set_visible(False)\n",
    "fig.axes.get_yaxis().set_visible(False)\n",
    "pylab.imshow(np.reshape(output_acts[100],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "for i in range(2,7):\n",
    "    fig = plt.subplot(170 + i)\n",
    "    plt.title(str(((i-1)*500)/float(1000)))\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    pylab.imshow(np.reshape(output_acts[(i-1)*500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "   \n",
    "fig2 = plt.subplot(177)\n",
    "plt.title(\"3\")\n",
    "fig2.axes.get_xaxis().set_visible(False)\n",
    "fig2.axes.get_yaxis().set_visible(False)\n",
    "pylab.imshow(np.reshape(output_acts[3000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the probe's output if it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The filename includes the number of neurons and which digit is being rotated\n",
    "filename = \"mental_rotation_output_ONE_\"  + str(n_hid) + \".p\"\n",
    "cPickle.dump(sim.data[probe], open( filename , \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "testing = output_acts[300]\n",
    "plt.subplot(131)\n",
    "pylab.imshow(np.reshape(testing,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get image\n",
    "#testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "#noise = np.random.random([28,28]).ravel()\n",
    "testing = node_func(0,testing)\n",
    "\n",
    "plt.subplot(132)\n",
    "pylab.imshow(np.reshape(testing,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=testing)\n",
    "\n",
    "#Get encoder outputs\n",
    "testing_filter = np.dot(testing_act,rotated_counter_after_encoder_weights_filter)\n",
    "\n",
    "#Get activities\n",
    "testing_filter = ens.neuron_type.rates(testing_filter, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "for i in range(5):\n",
    "    testing_filter = np.dot(testing_filter,rotated_counter_after_encoder_weights_filter)\n",
    "    testing_filter = ens.neuron_type.rates(testing_filter, sim.data[ens].gain, sim.data[ens].bias)\n",
    "    testing_filter = np.dot(testing_filter,activity_to_img_weights)\n",
    "    testing_filter = node_func(0,testing_filter)\n",
    "    _, testing_filter = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=testing_filter)\n",
    "\n",
    "\n",
    "#testing_rotate = np.dot(testing_rotate,rotation_weights)\n",
    "\n",
    "testing_filter = np.dot(testing_filter,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(133)\n",
    "pylab.imshow(np.reshape(testing_filter,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(X_train[0],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=X_train[0])\n",
    "\n",
    "testing_rotate = np.dot(testing_act,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_rotate,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letterO = np.dot(ZERO,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(161)\n",
    "pylab.imshow(np.reshape(letterO,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterL = np.dot(SEVEN,label_weights)\n",
    "for _ in range(30):\n",
    "    letterL = np.dot(letterL,rotation_weights)\n",
    "letterL = np.dot(letterL,activity_to_img_weights)\n",
    "plt.subplot(162)\n",
    "pylab.imshow(np.reshape(letterL,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterI = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(163)\n",
    "pylab.imshow(np.reshape(letterI,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(165)\n",
    "pylab.imshow(np.reshape(letterI,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterV = np.dot(SEVEN,label_weights)\n",
    "for _ in range(40):\n",
    "    letterV = np.dot(letterV,rotation_weights)\n",
    "letterV = np.dot(letterV,activity_to_img_weights)\n",
    "plt.subplot(164)\n",
    "pylab.imshow(np.reshape(letterV,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterA = np.dot(SEVEN,label_weights)\n",
    "for _ in range(10):\n",
    "    letterA = np.dot(letterA,rotation_weights)\n",
    "letterA = np.dot(letterA,activity_to_img_weights)\n",
    "plt.subplot(166)\n",
    "pylab.imshow(np.reshape(letterA,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
