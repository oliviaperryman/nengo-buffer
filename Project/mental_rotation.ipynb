{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import nengo\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import pylab\n",
    "from PIL import Image\n",
    "import nengo.spa as spa\n",
    "import cPickle\n",
    "\n",
    "from nengo_extras.data import load_mnist\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "\n",
    "#Encode categorical integer features using a one-hot aka one-of-K scheme.\n",
    "def one_hot(labels, c=None):\n",
    "    assert labels.ndim == 1\n",
    "    n = labels.shape[0]\n",
    "    c = len(np.unique(labels)) if c is None else c\n",
    "    y = np.zeros((n, c))\n",
    "    y[np.arange(n), labels] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- load the data\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
    "\n",
    "X_train = 2 * X_train - 1  # normalize to -1 to 1\n",
    "X_test = 2 * X_test - 1  # normalize to -1 to 1\n",
    "\n",
    "train_targets = one_hot(y_train, 10)\n",
    "test_targets = one_hot(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- set up network parameters\n",
    "#Want to encode and decode the image\n",
    "n_vis = X_train.shape[1]\n",
    "n_out =  X_train.shape[1]\n",
    "#number of neurons/dimensions of semantic pointer\n",
    "n_hid = 1000 #Try with more neurons for more accuracy\n",
    "#n_hid = 1000\n",
    "\n",
    "#Want the encoding/decoding done on the training images\n",
    "ens_params = dict(\n",
    "    eval_points=X_train,\n",
    "    neuron_type=nengo.LIFRate(), #Why not use LIF?\n",
    "    intercepts=nengo.dists.Choice([-0.5]),\n",
    "    max_rates=nengo.dists.Choice([100]),\n",
    "    )\n",
    "\n",
    "#Least-squares solver with L2 regularization.\n",
    "solver = nengo.solvers.LstsqL2(reg=0.01)\n",
    "#solver = nengo.solvers.LstsqL2(reg=0.0001)\n",
    "solver2 = nengo.solvers.LstsqL2(reg=0.01)\n",
    "\n",
    "#network that \n",
    "with nengo.Network(seed=3) as model:\n",
    "    a = nengo.Ensemble(n_hid, n_vis, seed=3, **ens_params)\n",
    "    v = nengo.Node(size_in=n_out)\n",
    "    conn = nengo.Connection(\n",
    "        a, v, synapse=None,\n",
    "        eval_points=X_train, function=X_train,#want the same thing out\n",
    "        solver=solver)\n",
    "    \n",
    "    v2 = nengo.Node(size_in=train_targets.shape[1])\n",
    "    conn2 = nengo.Connection(\n",
    "        a, v2, synapse=None,\n",
    "        eval_points=X_train, function=train_targets, #Want to get the labels out\n",
    "        solver=solver2)\n",
    "    \n",
    "    \n",
    "\n",
    "def get_outs(sim, images):\n",
    "    _, acts = nengo.utils.ensemble.tuning_curves(a, sim, inputs=images)\n",
    "    return np.dot(acts, sim.data[conn2].weights.T)\n",
    "\n",
    "def get_error(sim, images, labels):\n",
    "    return np.argmax(get_outs(sim, images), axis=1) != labels\n",
    "\n",
    "def get_labels(sim,images):\n",
    "    return np.argmax(get_outs(sim, images), axis=1)\n",
    "\n",
    "#Get the neuron activity of an image or group of images (this is the semantic pointer in this case)\n",
    "def get_activities(sim, images):\n",
    "    _, acts = nengo.utils.ensemble.tuning_curves(a, sim, inputs=images)\n",
    "    return acts\n",
    "\n",
    "def get_encoder_outputs(sim,images):\n",
    "    outs = np.dot(images,sim.data[a].encoders.T) #before the neurons Why transpose?\n",
    "    return outs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb98b6d8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Images to train for rotation of 90 deg\n",
    "orig_imgs = X_train[:10000].copy()\n",
    "\n",
    "rotated_imgs =X_train[:10000].copy()\n",
    "for img in rotated_imgs:\n",
    "    img[:] = scipy.ndimage.interpolation.rotate(np.reshape(img,(28,28)),90,reshape=False).ravel()\n",
    "\n",
    "\n",
    "test_imgs = X_test[:1000].copy()\n",
    "'''  \n",
    "\n",
    "#Images to train, starting at random orientation\n",
    "orig_imgs = X_train[:100000].copy()\n",
    "for img in orig_imgs:\n",
    "    img[:] = scipy.ndimage.interpolation.rotate(np.reshape(img,(28,28)),(np.random.randint(360)),reshape=False,mode=\"nearest\").ravel()\n",
    "\n",
    "#Images rotated a fixed amount from the original random orientation\n",
    "rotated_imgs =orig_imgs.copy()\n",
    "for img in rotated_imgs:\n",
    "    img[:] = scipy.ndimage.interpolation.rotate(np.reshape(img,(28,28)),6,reshape=False,mode=\"nearest\").ravel()\n",
    "\n",
    "    #^encoder outputs\n",
    "    \n",
    "#Images not used for training, but for testing (all at random orientations)\n",
    "test_imgs = X_test[:1000].copy()\n",
    "for img in test_imgs:\n",
    "    img[:] = scipy.ndimage.interpolation.rotate(np.reshape(img,(28,28)),(np.random.randint(360)),reshape=False,mode=\"nearest\").ravel()\n",
    "\n",
    "\n",
    "#Check that rotation is done correctly\n",
    "plt.subplot(121)\n",
    "plt.imshow(orig_imgs[5].reshape(28,28),cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(rotated_imgs[5].reshape(28,28),cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear filter used for edge detection as encoders, more plausible for human visual system\n",
    "encoders = Gabor().generate(n_hid, (11, 11), rng=rng)\n",
    "encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
    "#Set the ensembles encoders to this\n",
    "a.encoders = encoders\n",
    "\n",
    "#Check the encoders were correctly made\n",
    "plt.imshow(encoders[0].reshape(28, 28), vmin=encoders[0].min(), vmax=encoders[0].max(), cmap='gray')\n",
    "\n",
    "\n",
    "with nengo.Simulator(model) as sim:    \n",
    "    \n",
    "    #Neuron activities of different mnist images\n",
    "    #The semantic pointers\n",
    "    orig_acts = get_activities(sim,orig_imgs)\n",
    "    #rotated_acts = get_activities(sim,rotated_imgs)\n",
    "    #test_acts = get_activities(sim,test_imgs)\n",
    "    \n",
    "    #X_test_acts = get_activities(sim,X_test)\n",
    "    #labels_out = get_outs(sim,X_test)\n",
    "    \n",
    "    rotated_after_encoders = get_encoder_outputs(sim,rotated_imgs)\n",
    "    \n",
    "    #solvers for a learning rule\n",
    "    #solver_tranform = nengo.solvers.LstsqL2(reg=1e-8)\n",
    "    #solver_word = nengo.solvers.LstsqL2(reg=1e-8)\n",
    "    solver_rotate_encoder = nengo.solvers.LstsqL2(reg=1e-8)\n",
    "    \n",
    "    \n",
    "    #find weight matrix between neuron activity of the original image and the rotated image\n",
    "    #weights returns a tuple including information about learning process, just want the weight matrix\n",
    "    #weights,_ = solver_tranform(orig_acts, rotated_acts)\n",
    "    \n",
    "    #find weight matrix between labels and neuron activity\n",
    "    #label_weights,_ = solver_word(labels_out,X_test_acts)\n",
    "    \n",
    "    \n",
    "    rotated_after_encoder_weights,_ = solver_rotate_encoder(orig_acts,rotated_after_encoders)\n",
    "    \n",
    "    \n",
    "#cPickle.dump(rotated_after_encoder_weights, open( \"rotated_after_encoder_weights.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000L, 10L)\n"
     ]
    }
   ],
   "source": [
    "print(labels_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#test_targets[i]\n",
    "'''\n",
    "ZERO = test_targets[3]\n",
    "ONE = test_targets[2]\n",
    "TWO = test_targets[1]\n",
    "THREE = test_targets[30]\n",
    "FOUR = test_targets[19]\n",
    "FIVE = test_targets[8]\n",
    "SIX = test_targets[11]\n",
    "SEVEN = test_targets[17]\n",
    "EIGHT = test_targets[61]\n",
    "NINE = test_targets[7]\n",
    "'''\n",
    "\n",
    "temp = np.diag([1]*10)\n",
    "\n",
    "ZERO = temp[0]\n",
    "ONE =  temp[1]\n",
    "TWO =  temp[2]\n",
    "THREE= temp[3]\n",
    "FOUR = temp[4]\n",
    "FIVE = temp[5]\n",
    "SIX =  temp[6]\n",
    "SEVEN =temp[7]\n",
    "EIGHT= temp[8]\n",
    "NINE = temp[9]\n",
    "\n",
    "#Change this to imagine different digits\n",
    "imagine = EIGHT\n",
    "\n",
    "#Label to activity\n",
    "test_activity = np.dot(imagine,label_weights)\n",
    "#Image decoded \n",
    "test_output_img = np.dot(test_activity, sim.data[conn].weights.T)\n",
    "\n",
    "plt.imshow(test_output_img.reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import cPickle\n",
    "#cPickle.dump(label_weights, open( \"label_weights.p\", \"wb\" ) )\n",
    "#cPickle.dump(sim.data[conn].weights.T, open( \"activity_to_img_weights.p\", \"wb\" ) )\n",
    "#cPickle.dump(weights, open( \"rotation_weights.p\", \"wb\" ) )\n",
    "#cPickle.dump(rotated_after_encoder_weights, open( \"rotated_after_encoder_weights.p\", \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(1000)\n",
    "\n",
    "#Activity of the rotated semantic pointer, dot product of activity(semantic) and weight matrix \n",
    "test_output_act = np.dot(test_acts[i],weights)\n",
    "\n",
    "#Image decoded with no rotation\n",
    "test_output_img_unrot = np.dot(test_acts[i], sim.data[conn].weights.T)\n",
    "#Image decoded after rotation\n",
    "test_output_img = np.dot(test_output_act, sim.data[conn].weights.T)\n",
    "#Image rotated with no neurons\n",
    "output_img_rot = scipy.ndimage.interpolation.rotate(np.reshape(test_imgs[i],(28,28)),6,reshape=False,mode=\"nearest\").ravel()\n",
    "\n",
    "#Input image\n",
    "plt.subplot(141)\n",
    "plt.imshow(test_imgs[i].reshape(28,28),cmap='gray')\n",
    "#Decoded image, no rotation\n",
    "plt.subplot(142)\n",
    "plt.imshow(test_output_img_unrot.reshape(28,28),cmap='gray')\n",
    "#Rotated image, no neurons\n",
    "plt.subplot(143)\n",
    "plt.imshow(output_img_rot.reshape(28,28),cmap='gray')\n",
    "#Decoded image after rotation\n",
    "plt.subplot(144)\n",
    "plt.imshow(test_output_img.reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagine = THREE\n",
    "frames=60\n",
    "\n",
    "#Make a list of the rotated images and add first frame\n",
    "rot_seq = []\n",
    "rot_seq.append(np.dot(imagine,label_weights))\n",
    "test_output_img = np.dot(rot_seq[0], sim.data[conn].weights.T)\n",
    "\n",
    "#add the rest of the frames, using the previous frame to calculate the current frame\n",
    "for i in range(1,frames):\n",
    "    rot_seq.append(np.dot(rot_seq[i-1],weights))\n",
    "    test_output_img = np.dot(rot_seq[i], sim.data[conn].weights.T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Animation of rotation\n",
    "fig = plt.figure()\n",
    "\n",
    "def updatefig(i):\n",
    "    temp = np.dot(rot_seq[i], sim.data[conn].weights.T)\n",
    "    im = pylab.imshow(np.reshape(temp,(28,28), 'F').T, cmap=plt.get_cmap('Greys_r'),animated=True)\n",
    "    \n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, interval=100, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames=60\n",
    "\n",
    "rot_seq = []\n",
    "rot_seq.append(np.dot(test_acts[i],weights))\n",
    "test_output_img = np.dot(rot_seq[0], sim.data[conn].weights.T)\n",
    "\n",
    "#plt.subplot(1,frames,1)\n",
    "#plt.imshow(test_output_img.reshape(28,28),cmap='gray')\n",
    "\n",
    "for i in range(1,frames):\n",
    "    rot_seq.append(np.dot(rot_seq[i-1],weights))\n",
    "    test_output_img = np.dot(rot_seq[i], sim.data[conn].weights.T)\n",
    "    #plt.subplot(1,frames,i+1)\n",
    "    #plt.imshow(test_output_img.reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "def updatefig(i):\n",
    "    temp = np.dot(rot_seq[i], sim.data[conn].weights.T)\n",
    "    im = pylab.imshow(np.reshape(temp,(28,28), 'F').T, cmap=plt.get_cmap('Greys_r'),animated=True)\n",
    "    \n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, interval=100, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "--- Ignore ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Image.open(\"export.png\")\n",
    "a = np.array(a)\n",
    "\n",
    "\n",
    "pylab.imshow(a,cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_imgs = X_train[:10].copy()\n",
    "#= np.ndarray((10,784),dtype=np.ndarray)\n",
    "ordered_imgs[0] = X_train[1]\n",
    "ordered_imgs[0] = X_train[8]\n",
    "ordered_imgs[0] = X_train[25]\n",
    "ordered_imgs[0] = X_train[12]\n",
    "ordered_imgs[0] = X_train[26]\n",
    "ordered_imgs[0] = X_train[47]\n",
    "ordered_imgs[0] = X_train[18]\n",
    "ordered_imgs[0] = X_train[29]\n",
    "ordered_imgs[0] = X_train[46]\n",
    "ordered_imgs[0] = X_train[22]\n",
    "\n",
    "names = np.ndarray((10,10),dtype=np.ndarray)\n",
    "\n",
    "for i in range(10):\n",
    "    names[i] = spa.SemanticPointer(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
