{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the trained weights in an ensemble of neurons\n",
    "- On the function points branch of nengo\n",
    "- On the vision branch of nengo_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nengo\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from nengo_extras.data import load_mnist\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- load the data\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
    "\n",
    "X_train = 2 * X_train - 1  # normalize to -1 to 1\n",
    "X_test = 2 * X_test - 1  # normalize to -1 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit is represented by a one hot vector where the index of the 1 represents the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = np.diag([1]*10)\n",
    "\n",
    "ZERO = temp[0]\n",
    "ONE =  temp[1]\n",
    "TWO =  temp[2]\n",
    "THREE= temp[3]\n",
    "FOUR = temp[4]\n",
    "FIVE = temp[5]\n",
    "SIX =  temp[6]\n",
    "SEVEN =temp[7]\n",
    "EIGHT= temp[8]\n",
    "NINE = temp[9]\n",
    "\n",
    "labels =[ZERO,ONE,TWO,THREE,FOUR,FIVE,SIX,SEVEN,EIGHT,NINE]\n",
    "\n",
    "dim =28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved weight matrices that were created by trainging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_weights = cPickle.load(open(\"label_weights1000.p\", \"rb\"))\n",
    "activity_to_img_weights = cPickle.load(open(\"activity_to_img_weights1000.p\", \"rb\"))\n",
    "identity_after_encoder_weights =  cPickle.load(open(\"identity_after_encoder_weights1000.p\", \"r\"))\n",
    "#rotated_after_encoder_weights_5000 =  cPickle.load(open(\"rotated_after_encoder_weights_5000.p\", \"r\"))\n",
    "\n",
    "#rotation_weights = cPickle.load(open(\"rotation_weights_clockwise5000.p\",\"rb\"))\n",
    "\n",
    "#label_weights = cPickle.load(open(\"label_weights_rot_enc5000.p\", \"rb\"))\n",
    "#activity_to_img_weights = cPickle.load(open(\"activity_to_img_weights_rot_enc5000.p\", \"r\"))\n",
    "#rotated_after_encoder_weights =  cPickle.load(open(\"rotated_counter_after_encoder_weights_rot_enc5000.p\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network where the mental imagery occurs\n",
    "- The state, seed and ensemble parameters (including encoders) must all be the same for the saved weight matrices to work\n",
    "- The number of neurons (n_hid) must be the same as was used for training\n",
    "- The input must be shown for a short period of time to be able to view the image\n",
    "- The recurrent connection must be from the neurons because the weight matices were trained on the neuron activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(9)\n",
    "n_hid = 1000\n",
    "model = nengo.Network(seed=3)\n",
    "with model:\n",
    "    #Stimulus only shows for brief period of time\n",
    "    stim = nengo.Node(lambda t: THREE if t < 0.1 else 0) #nengo.processes.PresentInput(labels,1))#\n",
    "    \n",
    "    ens_params = dict(\n",
    "        eval_points=X_train,\n",
    "        neuron_type=nengo.LIF(),\n",
    "        intercepts=nengo.dists.Choice([-0.5]),\n",
    "        max_rates=nengo.dists.Choice([100]),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # linear filter used for edge detection as encoders, more plausible for human visual system\n",
    "    encoders = Gabor().generate(n_hid, (11, 11), rng=rng)\n",
    "    encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
    "\n",
    "    \n",
    "    ens = nengo.Ensemble(n_hid, dim**2, seed=3, encoders=encoders, **ens_params)\n",
    "    \n",
    "    #Recurrent connection on the neurons of the ensemble to maintain the image\n",
    "    nengo.Connection(ens.neurons, ens.neurons, transform = identity_after_encoder_weights.T, synapse=0.2)      \n",
    "    #Can't just connect neurons to neurons\n",
    "    #nengo.Connection(ens.neurons, ens.neurons, synapse=0.2)      \n",
    "\n",
    "    #Connect stimulus to ensemble, transform using learned weight matrices\n",
    "    nengo.Connection(stim, ens, transform = np.dot(label_weights,activity_to_img_weights).T, synapse=0.1)\n",
    "    \n",
    "    #Collect output, use synapse for smoothing\n",
    "    probe = nengo.Probe(ens.neurons,synapse=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 0:00:08.                                                 \n"
     ]
    }
   ],
   "source": [
    "sim.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is not part of the brain model, it is used to view the output for the ensemble\n",
    "Since it's probing the neurons themselves, the output must be transformed from neuron activity to visual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d4eda138fd3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mani\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manimation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFuncAnimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdatefig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\matplotlib\\pyplot.pyc\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \"\"\"\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\matplotlib\\backend_bases.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'WebAgg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\matplotlib\\backends\\backend_tkagg.pyc\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mShowBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mTk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\lib-tk\\Tkinter.pyc\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;34m\"\"\"Run the main loop of Tcl.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m     \u001b[0m_default_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[0mgetint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tk'"
     ]
    }
   ],
   "source": [
    "'''Animation for Probe output'''\n",
    "fig = plt.figure()\n",
    "\n",
    "output_acts = []\n",
    "for act in sim.data[probe]:\n",
    "    output_acts.append(np.dot(act,activity_to_img_weights))\n",
    "\n",
    "def updatefig(i):\n",
    "    im = pylab.imshow(np.reshape(output_acts[i],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'),animated=True)\n",
    "    \n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, interval=0.1, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(sim.data[probe]))\n",
    "\n",
    "plt.subplot(161)\n",
    "plt.title(\"100\")\n",
    "pylab.imshow(np.reshape(output_acts[100],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(162)\n",
    "plt.title(\"500\")\n",
    "pylab.imshow(np.reshape(output_acts[500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(163)\n",
    "plt.title(\"1000\")\n",
    "pylab.imshow(np.reshape(output_acts[1000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(164)\n",
    "plt.title(\"1500\")\n",
    "pylab.imshow(np.reshape(output_acts[1500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(165)\n",
    "plt.title(\"2000\")\n",
    "pylab.imshow(np.reshape(output_acts[2000],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(166)\n",
    "plt.title(\"2500\")\n",
    "pylab.imshow(np.reshape(output_acts[2500],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the probe's output if it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The filename includes the number of neurons and which digit is being rotated\n",
    "filename = \"mental_rotation_output_ONE_\"  + str(n_hid) + \".p\"\n",
    "cPickle.dump(sim.data[probe], open( filename , \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(testing,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get image\n",
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=testing)\n",
    "\n",
    "#Get rotated encoder outputs\n",
    "testing_rotate = np.dot(testing_act,rotated_after_encoder_weights)\n",
    "\n",
    "#Get activities\n",
    "testing_rotate = ens.neuron_type.rates(testing_rotate, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "for i in range(5):\n",
    "    testing_rotate = np.dot(testing_rotate,rotated_after_encoder_weights)\n",
    "    testing_rotate = ens.neuron_type.rates(testing_rotate, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "\n",
    "#testing_rotate = np.dot(testing_rotate,rotation_weights)\n",
    "\n",
    "testing_rotate = np.dot(testing_rotate,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_rotate,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(X_train[0],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=X_train[0])\n",
    "\n",
    "testing_rotate = np.dot(testing_act,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_rotate,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
