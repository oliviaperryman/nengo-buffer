{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pylab\n",
    "import nengo\n",
    "import random\n",
    "import numpy as np\n",
    "import gzip as gz\n",
    "import cPickle\n",
    "from cPickle import load\n",
    "try:\n",
    "    import Image\n",
    "except ImportError:\n",
    "    from PIL import Image\n",
    "from scipy.sparse.linalg import svds\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "#%matplotlib inline #Makes visualizations appar inline (Commented out because animation popup as new window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The code in this cell is for reading the images from the MNIST database and not part of the brain model.\n",
    "def load_img(path, dims):\n",
    "    \"\"\"Load the image at path and return an array representing the raster.\n",
    "    Flattens image. Shifts pixel activations such that 0 represents gray,\n",
    "    normalizes the output array.\n",
    "    Keyword arguments:\n",
    "    path -- str, path of the image to be loaded.\n",
    "    dims -- (w, h), where w,h are ints indicating dimensions of the image (in\n",
    "        px).\"\"\"\n",
    "\n",
    "    img = Image.open(path).resize(dims).getdata()\n",
    "    img.convert('L')\n",
    "    img = subtract(array(img).flatten(), 127.5)\n",
    "    return img/norm(img)\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"Uncompress, unpickle and return a .pkl.gz file.\n",
    "    Keyword arguments:\n",
    "    filename -- str, a valid file path\"\"\"\n",
    "\n",
    "    return load(gz.open(filename))\n",
    "\n",
    "def load_mini_mnist(option=None):\n",
    "    \"\"\"Load and return the first \\%10 of the images in the mnist dataset.\n",
    "    Does not return labels. Pass in 'train', 'valid' or 'test' if you want to\n",
    "    load a specific subset of the dataset.\n",
    "    Keyword arguments:\n",
    "    option -- str (default=None).\"\"\"\n",
    "\n",
    "    mini_mnist = load(gz.open('./mini_mnist.pkl.gz', 'rb'))\n",
    "    if option == 'train':\n",
    "        return mini_mnist[0]\n",
    "    elif option == 'valid':\n",
    "        return mini_mnist[1]\n",
    "    elif option == 'test':\n",
    "        return mini_mnist[2]\n",
    "    else:\n",
    "        return mini_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rotate_img(img, degrees):\n",
    "    '''\n",
    "    img is the dim**2 by 1 vector representing the pixel values.\n",
    "    Rotates image the degrees passed in counterclockwise\n",
    "    Returns the Reshaped image (to original shape which is the one dimensional vector)\n",
    "    dim is a global variable\n",
    "    '''\n",
    "    original = img.shape\n",
    "    \n",
    "    newImg = scipy.ndimage.interpolation.rotate(np.reshape(img, (dim,dim), 'F'),degrees,reshape=False)\n",
    "    newImg = np.reshape(newImg, original, 'F')\n",
    "    return newImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_synapse = 0.1 #post synaptic time constant to use for filtering (pstc) - what does changing this do?\n",
    "probe_synapse = 0.01 #pstc\n",
    "multiplier = 2 #not used\n",
    "n_neurons = 5000\n",
    "direct = False #Direct - function computed explicitly instead of in neurons \n",
    "stop_time = 3.0\n",
    "run_time = 3.0 #in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim = 28 #size of the image\n",
    "mnist = load_mini_mnist()\n",
    "#train = mnist[0] #collection of training images\n",
    "img = mnist[1][0] #image to be used for testing\n",
    "#compress_size = 400 #?\n",
    "#basis, S, V = svds(train.T, k=compress_size) #Used for encoding and decoding information \n",
    "    #a set of vectors representing what a hand drawn number should look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Need same number of vectors in basis as number of neurons (randomly sample from basis)\n",
    "#expanded_basis = np.array([random.choice(basis.T) for _ in range(n_neurons)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stim_func(t):\n",
    "    '''returns the image for first 0.1s'''\n",
    "    if t < 0.1:\n",
    "        return img\n",
    "    else:\n",
    "        return [0 for _ in range(len(img))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connection_func(x):\n",
    "    '''takes the output from the first ensemble and rotates it 1 degree'''\n",
    "    return rotate_img(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A network is primarily used for grouping together related objects and connections for visualization purposes\n",
    "with nengo.Network() as net:\n",
    "    \n",
    "    if direct:\n",
    "        neuron_type = nengo.Direct() #function computed explicitly, instead of in neurons\n",
    "    else:\n",
    "        neuron_type = nengo.LIF() #spiking version of the leaky integrate-and-fire neuron model\n",
    "\n",
    "    #Input stimulus - provide data to the ensemble\n",
    "    ipt = nengo.Node(stim_func)\n",
    "    \n",
    "    '''An array of ensembles. This acts, in some ways, like a single high-dimensional ensemble,\n",
    "    but actually consists of many sub-ensembles, each one representing a separate dimension. \n",
    "    This tends to be much faster to create and can be more accurate than having one huge \n",
    "    high-dimensional ensemble. However, since the neurons represent different dimensions separately,\n",
    "    we cannot compute nonlinear interactions between those dimensions.'''\n",
    "    ensArr = nengo.networks.EnsembleArray(100, dim**2, ens_dimensions=1,neuron_type=neuron_type) #incresing num neurons has small effect on run time\n",
    "    \n",
    "    #Connect each pixel of the input to its own ensemble\n",
    "    nengo.Connection(ipt,ensArr.input)\n",
    "    \n",
    "    '''When connecting nodes, threw error: \n",
    "    Validation error when setting 'Connection.function_info': Cannot apply functions to passthrough nodes\n",
    "    This is a workaround (https://github.com/nengo/nengo/issues/805)'''\n",
    "    ensArr.output.output=lambda t, x: x\n",
    "\n",
    "    #output node of ensArr brings all pixels together, connection performs the rotation and feeds into input node of ensArr\n",
    "    nengo.Connection(ensArr.output, ensArr.input, function=connection_func)\n",
    "\n",
    "    #Gathering output of ensArr\n",
    "    probe = nengo.Probe(ensArr.output,# attr='decoded_output',#sample_every=0.001,\n",
    "                       synapse=probe_synapse)\n",
    "        \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(net) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 0:02:26.                                                 \n"
     ]
    }
   ],
   "source": [
    "sim.run(run_time) #LIF 2:25 #Direct 0:25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3afdf4a8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original image\n",
    "pylab.imshow(np.reshape(img, (dim,dim), 'F'), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3bbccc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Image at stop time'''\n",
    "pylab.imshow(np.reshape([0. if x < 0.00001 else x for x in sim.data[probe][int(stop_time*1000)-1]], \n",
    "                             (dim, dim), 'F'), cmap=plt.get_cmap('Greys_r'),animated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3afdffd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Image at start time'''\n",
    "pylab.imshow(np.reshape([0. if x < 0.00001 else x for x in sim.data[probe][1]], \n",
    "                             (dim, dim), 'F'), cmap=plt.get_cmap('Greys_r'),animated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Animation for Probe output'''\n",
    "fig = plt.figure()\n",
    "\n",
    "def updatefig(i):\n",
    "    im = pylab.imshow(np.reshape([0. if x < 0.00001 else x for x in sim.data[probe][i]],\n",
    "                                 (dim, dim), 'F'), cmap=plt.get_cmap('Greys_r'),animated=True)\n",
    "    \n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, interval=1, blit=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the output\n",
    "#cPickle.dump(sim.data[probe], open( \"Buffer_rotations_in_connection_ensemble_array_direct.p\", \"wb\" ) )\n",
    "#cPickle.dump(sim.data[probe], open( \"Buffer_rotations_in_connection_ensemble_array_LIF_100.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
